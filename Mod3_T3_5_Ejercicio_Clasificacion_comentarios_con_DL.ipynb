{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mod3_T3-5_Ejercicio_Clasificacion_comentarios_con_DL.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wilmerod/Curso-de-introduccion-a-Big-Data-Parte-1-nov2021/blob/main/Mod3_T3_5_Ejercicio_Clasificacion_comentarios_con_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo de clasificación de valoraciones de películas con deep learning\n",
        "\n",
        "Trabajamos con el dataset IMDB, que ya viene preprocesado y el texto se ha codificado como una secuencia de números enteros.\n",
        "\n",
        "Viene precargado en la librería Keras: https://keras.io/api/datasets/imdb/"
      ],
      "metadata": {
        "id": "bDAoSmoXuaa7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxDcPUiQSiPq"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "(train_data, train_labels), (test_data,test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbPHcUXQTRy7"
      },
      "source": [
        "Vemos que train_data y test_data son listas de índices correspondientes a palabras presentes en una review de una película"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql5C33tES6CU"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkgwaeabTK3n"
      },
      "source": [
        "Por otro lado, train_labels y test_labels son listas de 0 y 1, correspondiendo el 0 a una valoración negativa y el 1 a una valoración positiva"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbuYeHqkTAbp",
        "outputId": "f773cd57-b842-41d8-a9df-5ed57c30c615"
      },
      "source": [
        "train_labels[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El módulo incluye la función get_word_index, que es la que codifica el texto a índices. El criterio de codificación asigna a cada palabra el número entero correspondiente al orden que ocupa dicha palabra en cuanto a frecuencia de aparición en el dataset. Para recuperar el texto literal, invertimos índices y valores tras aplicar la función."
      ],
      "metadata": {
        "id": "-bVjCD6ixVuy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qmQpJCDT9AO"
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict(\n",
        "    [(value,key) for (key,value) in word_index.items()]\n",
        ")\n",
        "decoded_review = ' '.join(\n",
        "    [reverse_word_index.get(i - 3, '?') for i in train_data[0]]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "bbRRZd6hU2VL",
        "outputId": "4ce8bdbc-5df3-48a3-8eb6-e92216efa5f0"
      },
      "source": [
        "decoded_review"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparamos los datos de entrada\n",
        "No podemos introducir en la red neuronal listas de diferente longitud. Las redes neuronales solo aceptan tensores, y tenemos que \"vectorizar\" las listas de los comentarios."
      ],
      "metadata": {
        "id": "Q6IzpNf17Wht"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd_0o5yNVClh"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "  results = np.zeros((len(sequences), dimension))\n",
        "  for i, sequence in enumerate(sequences):\n",
        "    results[i, sequence] = 1.\n",
        "  return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0]"
      ],
      "metadata": {
        "id": "u61DzCKiMYBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convertimos en array también las etiquetas y"
      ],
      "metadata": {
        "id": "3wCPFnqt9DFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ],
      "metadata": {
        "id": "oO5p962yMyYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construimos el modelo\n",
        "Creamos un modelo Sequential con 3 capas neuronales, dos de 16 neuronas y la de salida con 1 neurona, pues es un problema de clasificación binario"
      ],
      "metadata": {
        "id": "jP-YrSYK9JSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QY6bUAT_M1HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fijamos los parámetros del entrenamiento\n",
        "Podemos ustilizar el módulo optimizers para fijar parámetros internos del oprimizador."
      ],
      "metadata": {
        "id": "wF_ziTK_GzDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1wMiJPHpM5Bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reservamos datos para la validación."
      ],
      "metadata": {
        "id": "_P3XtFRxHP2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3rMO7BndM97J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamos el modelo"
      ],
      "metadata": {
        "id": "v-8L_GzNHuA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LBPXiBmONZN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Representamos la evolución del error y la precisión en cada epoch"
      ],
      "metadata": {
        "id": "5cVYCPktZiFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1ntFHhAdN2zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el momento en que la precisión del modelo con los datos de entrenamiento aumenta pero la de los datos de validación no, tenemos indicios de que se está dando lo que se denomina \"overfitting\". Volvemos a entrenar un nuevo modelo pero, esta vez, solo con 4 epochs"
      ],
      "metadata": {
        "id": "i0wwEiLqQdw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2mlwkzczWW84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probamos a hacer una predicción"
      ],
      "metadata": {
        "id": "8MHZZ4VAWzEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HwAlr_mMXFyv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}